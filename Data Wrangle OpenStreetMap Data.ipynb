{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangle OpenStreetMap Data\n",
    "\n",
    "Map Area: Jersey City, New Jersey, USA\n",
    "\n",
    "Map links for Jersey City     \n",
    "https://www.openstreetmap.org/relation/170953    \n",
    "http://overpass-api.de/api/map?bbox=-74.2432,40.6343,-73.8944,40.7961\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "OpenStreepMap is a collaborative project to create free editable map of the world. Its similar to Wikipedia in sourcing data.\n",
    "Data from OSM can be exported in XML format (.osm). This data can be analyzed and used in different projects. Data is availabe under Open Database License.\n",
    "\n",
    "More details regarding OSM and .osm data format can be found below:\n",
    "https://en.wikipedia.org/wiki/OpenStreetMap\n",
    "http://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "\n",
    "### Map Area\n",
    "\n",
    "In this project, I will be analyzing selected map area (Jersey City, NJ) data quality (DQ) for validity, accuracy, consistency and uniformity. I will be wrangling xml format of data using Python. After some DQ checks and cleaning some data, I will be storing data to MongoDB. Then I will be performing some queries and data aggregations to get some information about data.\n",
    "\n",
    "I selected Jersey city (JC), because its my current work location. Jersey City is most ethnically diverse cities in the world and fourth most densely populated city in the United States. It is part of New York Metropolitan area also.\n",
    "I tried downloading JC data from openstreetmap export option, but it failed. Then I decided to use overpass-api to download data. I am using Python HTTP library - Requests to get the data.\n",
    "\n",
    "Below code will download Jersey City map data in jersey_city.osm file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# overpass url for jersey city, nj\n",
    "url = 'http://overpass-api.de/api/map?bbox=-74.2432,40.6343,-73.8944,40.7961'\n",
    "filename = 'jersey_city.osm'\n",
    "\n",
    "\n",
    "def download_osm(url, filename):\n",
    "    r = requests.get(url, stream = True) # http get to download the data\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "download_osm(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am including below map area to show the area covered in analysis. When I got the co-ordinate range for jersey city from openstreetmap, I did not realize it was not exactly for Jersey City, but it covered many neighbouring areas. By the time I realized it, I was very further in project, so I decided to continue and use these co-ordinates as my area of interest.  Please note, Jersey City term in this project will include Jersey City and other areas in these co-ordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"425\" height=\"350\" frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" src=\"http://www.openstreetmap.org/export/embed.html?bbox=-74.25212860107422%2C40.64730356252251%2C-73.98914337158203%2C40.809131953785965&amp;layer=mapnik\" style=\"border: 1px solid black\"></iframe><br/><small><a href=\"http://www.openstreetmap.org/#map=12/40.7283/-74.1206\">View Larger Map</a></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<iframe width=\"425\" height=\"350\" frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" src=\"http://www.openstreetmap.org/export/embed.html?bbox=-74.25212860107422%2C40.64730356252251%2C-73.98914337158203%2C40.809131953785965&amp;layer=mapnik\" style=\"border: 1px solid black\"></iframe><br/><small><a href=\"http://www.openstreetmap.org/#map=12/40.7283/-74.1206\">View Larger Map</a></small>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Problems Encountered in the Map\n",
    "\n",
    "### Map Parsing\n",
    "\n",
    "I will parse osm file using ElementTree to find out different tags present in the file. Keeping the size of the file in the mind, I will use SAX parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 84098,\n",
      " 'meta': 1,\n",
      " 'nd': 2457737,\n",
      " 'node': 1721029,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 2450,\n",
      " 'tag': 2000510,\n",
      " 'way': 312552}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    osm_file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "    \n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(filename)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 1.7 millions nodes defined. Also, big number of ways are defined.\n",
    "There are 2000510 tags present in the file. These tags are name-value pair, to define multiple attributes of nodes or ways.\n",
    "\n",
    "Also, for my final data model for MongoDB, I will be grouping similar tags (like address). I will further audit tags to find some pattern and to remove problematic/invalid data for MongoDB. I will try to make sure if these values can be valid keys for MongoDB.\n",
    "\n",
    "I am using Python regular expression to perform this auditing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 742444,\n",
      " 'lower_colon': 1222919,\n",
      " 'other': 15181,\n",
      " 'problemchars': 19966}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# define regular expressions\n",
    "lower = re.compile(r'^([a-z]|_)*$') # reg-ex for lower case\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$') # reg-ex for lower case and presence of colon (:)\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]') # reg-ex for probelm chars not allowed for MongoDB keys\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.search(element.attrib[\"k\"]):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map(filename)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19966 tags with problem characters which can cause issue while loading to MongoDB.\n",
    "With some further exploring, I can find tags with keys : \"addr:\"\n",
    "I will be grouping by \"addr:\" under \"address\" key in data model. lower_colon will help to find these keys.\n",
    "\n",
    "I will do more exploring of data, this time to find out about users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Users: 1556\n"
     ]
    }
   ],
   "source": [
    "def get_user(element, user):\n",
    "    user = \"\"\n",
    "    at = element.attrib\n",
    "    \n",
    "    for key in at:\n",
    "        if key == \"user\" and at[\"user\"] != \"\":\n",
    "            user = at[\"user\"]\n",
    "    return user\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user = get_user(element, users)\n",
    "        if user != \"\":\n",
    "            users.add(user)\n",
    "    return users \n",
    "\n",
    "users = process_map(filename)\n",
    "print(\"Number of Unique Users: {}\".format(len(users))) # Getting number of Unique Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent Street Names\n",
    "Street Names present in this map data is inconsistent. Since data is crowd sourced, there is no standard in mentioning street names and addresses. Many street names are over abbreviated.\n",
    "In first problem finding exercise I will try to find such inconsistencies in street names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10024': {'West 80th Street NYC 10024'},\n",
      " '1801': {'505th 8th Avenue Suite 1801'},\n",
      " '1st': {'1st'},\n",
      " '27th': {'W 27th'},\n",
      " '29th': {'29th'},\n",
      " '2N': {'400th West 20th St., Suite 2N'},\n",
      " '3': {'Hanover Square #3'},\n",
      " '300': {'Ste 300'},\n",
      " '306': {'West 30th Street Suite 306'},\n",
      " '41st': {'41st'},\n",
      " '42nd': {'West 42nd'},\n",
      " '4B': {'Union Avenue 4B'},\n",
      " '500': {'Main St., Suite 500'},\n",
      " '633': {'633'},\n",
      " '861': {'861'},\n",
      " 'A': {'Avenue A'},\n",
      " 'Americas': {'Avenue Of The Americas',\n",
      "              'Avenue of Americas',\n",
      "              'Avenue of the Americas'},\n",
      " 'Atrium': {'Broadway Atrium'},\n",
      " 'Ave': {' Westminster Ave',\n",
      "         '4th Ave',\n",
      "         '5th Ave',\n",
      "         '64th St and 5th Ave',\n",
      "         '6th Ave',\n",
      "         'Hudson Ave',\n",
      "         'Norman Ave',\n",
      "         'Park Ave',\n",
      "         'Third Ave',\n",
      "         'Willow Ave'},\n",
      " 'Ave.': {'Washington Ave.', 'Springfield Ave.'},\n",
      " 'Avene': {'Nostrand Avene', 'Madison Avene'},\n",
      " 'Avenue,#392': {'Columbus Avenue,#392'},\n",
      " 'B': {'Avenue B'},\n",
      " 'Blv.': {'John F. Kennedy Blv.'},\n",
      " 'Blvd': {'Marin Blvd', 'Queens Blvd'},\n",
      " 'Bowery': {'Bowery', 'The Bowery'},\n",
      " 'Broadway': {'East Broadway', 'Broadway', 'West Broadway'},\n",
      " 'Bushwick': {'Bushwick'},\n",
      " 'C': {'Avenue C'},\n",
      " 'Center': {'Gotham Center',\n",
      "            'Metrotech Center',\n",
      "            'World Financial Center',\n",
      "            'World Trade Center'},\n",
      " 'Circle': {'Columbus Circle',\n",
      "            'Fort Hill Circle',\n",
      "            'Hell Gate Circle',\n",
      "            'Laguardia Circle',\n",
      "            'Mc Ginty Circle',\n",
      "            'Thelonious Monk Circle',\n",
      "            'Tompkins Circle'},\n",
      " 'Clinton': {'Clinton'},\n",
      " 'Crescent': {'Mt Olivet Crescent'},\n",
      " 'Ct.': {'Riverside Ct.'},\n",
      " 'Ctr': {'Harborside Fin Ctr'},\n",
      " 'D': {'Avenue D'},\n",
      " 'East': {'Anthony J Falco Square East',\n",
      "          'Cadman Plaza East',\n",
      "          'Fdr Drive Service Road East',\n",
      "          'Gouverneur Slip East',\n",
      "          'Gramercy Park East',\n",
      "          'Marginal St East',\n",
      "          'Plaza Street East',\n",
      "          'Union Square East',\n",
      "          'Washington Square East',\n",
      "          'Williamsburg Street East'},\n",
      " 'Extension': {'Eastern Parkway Extension', 'Flatbush Avenue Extension'},\n",
      " 'Finest': {'Avenue Of The Finest'},\n",
      " 'Floor': {'Broadway 21st Floor'},\n",
      " 'Floor)': {'Manhattan Avenue (2nd Floor)'},\n",
      " 'Fulton': {'Old Fulton'},\n",
      " 'Gratta': {'Gratta'},\n",
      " 'Heights': {'Columbia Heights'},\n",
      " 'Highway': {'McCarter Highway', 'Kings Highway'},\n",
      " 'Hudson': {'Castle Point on Hudson'},\n",
      " 'Island': {'Governors Island', 'Randalls Island', 'Wards Island'},\n",
      " 'J': {'Avenue J'},\n",
      " 'K': {'Avenue K'},\n",
      " 'L': {'Avenue L'},\n",
      " 'Landing': {'Bay Street Landing'},\n",
      " 'Loop': {'Charles Gay Loop',\n",
      "          'Margo Loop',\n",
      "          'Sunken Garden Loop',\n",
      "          'Wards Meadow Loop'},\n",
      " 'M': {'Avenue M'},\n",
      " 'Macdougal': {'Macdougal'},\n",
      " 'Mall': {'Centre Mall'},\n",
      " 'MetroTech': {'MetroTech'},\n",
      " 'Mews': {'Washington Mews', 'Greenwich Mews'},\n",
      " 'NY': {'54th W 39th St New York, NY'},\n",
      " 'North': {'Astoria Boulevard North',\n",
      "           'Brooklyn Queens Expressway West Service Road North',\n",
      "           'Gramercy Park North',\n",
      "           'Queens Plaza North',\n",
      "           'Saint Austins Place North',\n",
      "           'Washington Square North'},\n",
      " 'Oval': {'Stuyvesant Oval', 'Grand Army Plaza Oval'},\n",
      " 'PH': {'Harrison Street Suite PH'},\n",
      " 'Park': {'FDR Four Freedoms Park',\n",
      "          'Fort Hill Park',\n",
      "          'Gramercy Park',\n",
      "          'Washington Park'},\n",
      " 'Piers': {'Northside Piers'},\n",
      " 'Plz': {'University Plz'},\n",
      " 'Rd': {'43rd Rd'},\n",
      " 'Remsen': {'Remsen'},\n",
      " 'Rico': {'Avenue Of Puerto Rico'},\n",
      " 'Roadbed': {'4th Avenue Southbound Roadbed',\n",
      "             'Delancey Street Eb Roadbed',\n",
      "             'Delancey Street Wb Roadbed',\n",
      "             'Kings Highway Westbound Roadbed',\n",
      "             'Ocean Parkway Southbound Roadbed'},\n",
      " 'Row': {'Park Row'},\n",
      " 'S': {'Central Park S'},\n",
      " 'ST': {'N 9th ST'},\n",
      " 'Slip': {'Catherine Slip',\n",
      "          'Coenties Slip',\n",
      "          'Old Slip',\n",
      "          'Peck Slip',\n",
      "          'Pike Slip',\n",
      "          'Rutgers Slip'},\n",
      " 'South': {'7th Avenue South',\n",
      "           'Astoria Boulevard South',\n",
      "           'Astoria Park South',\n",
      "           'Brooklyn Queens Expressway West Service Road South',\n",
      "           'Central Park South',\n",
      "           'Craig Road South',\n",
      "           'Delancey St South',\n",
      "           'Gramercy Park South',\n",
      "           'Hoyt Avenue South',\n",
      "           'Mc Guinness Boulevard South',\n",
      "           'Park Avenue South',\n",
      "           'Queens Plaza South',\n",
      "           'Saint Austins Place South',\n",
      "           'Sutton Place South',\n",
      "           'Washington Square South'},\n",
      " 'Southwest': {'Prospect Park Southwest'},\n",
      " 'Springfield': {'Springfield'},\n",
      " 'St': {'1st St',\n",
      "        '2nd St',\n",
      "        '330 E 84th St',\n",
      "        '362nd Grand St',\n",
      "        '3rd St',\n",
      "        '40 W 94th St',\n",
      "        '4th St',\n",
      "        '6th St',\n",
      "        '7th St',\n",
      "        '8th St',\n",
      "        '9th St',\n",
      "        'Adams St',\n",
      "        'Bloomfield St',\n",
      "        'Clinton St',\n",
      "        'Court St',\n",
      "        'Garden St',\n",
      "        'Grand St',\n",
      "        'Hudson St',\n",
      "        'Jackson St',\n",
      "        'Jefferson St',\n",
      "        'Madison St',\n",
      "        'Monroe St',\n",
      "        'N 7th St',\n",
      "        'Newark St',\n",
      "        'River St',\n",
      "        'Smith St & Bergen St',\n",
      "        'Washington St',\n",
      "        'West 32nd St'},\n",
      " 'St.': {'11th St.',\n",
      "         '9th St.',\n",
      "         'Devoe St.',\n",
      "         'E. 54th St.',\n",
      "         'East 73rd St.',\n",
      "         'East 86th St.',\n",
      "         'Henry St.',\n",
      "         'South 4th St.',\n",
      "         'Warren St.',\n",
      "         'Washington St.',\n",
      "         'West 44th St.'},\n",
      " 'Steet': {'West 8th Steet'},\n",
      " 'Streeet': {'Johnson Streeet'},\n",
      " 'Vanderbilt': {'Vanderbilt'},\n",
      " 'Village': {'Washington Square Village'},\n",
      " 'Warren': {'Warren'},\n",
      " 'West': {'Cadman Plaza West',\n",
      "          'Central Park West',\n",
      "          'Fdr Drive Service Road West',\n",
      "          'Gouverneur Slip West',\n",
      "          'Gramercy Park West',\n",
      "          'Marginal Street West',\n",
      "          'Plaza St West',\n",
      "          'Prospect Park West',\n",
      "          'Union Square West',\n",
      "          'Washington Square West',\n",
      "          'Williamsburg Street West'},\n",
      " 'Willoughby': {'Willoughby'},\n",
      " 'Woodside': {'Woodside'},\n",
      " 'ave': {'6th ave', '5th ave'},\n",
      " 'avenue': {'2nd avenue', 'Bedford avenue', 'Utica avenue'},\n",
      " 'bus_stop': {'bus_stop'},\n",
      " 'south': {'Us Highway 1 and 9 south'},\n",
      " 'st': {'South 4th st', 'W 35th st', 'Union st'},\n",
      " 'street': {'5th street',\n",
      "            'Columbia street',\n",
      "            'E 45th street',\n",
      "            'East 5th street',\n",
      "            'Hudson street',\n",
      "            'Lafayette street',\n",
      "            'Mott street',\n",
      "            'Rivington street',\n",
      "            'Steinway street',\n",
      "            'Union street',\n",
      "            'W. 44th street',\n",
      "            'West 51st street',\n",
      "            'West 57th street',\n",
      "            'west 55th street'}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# RegEx to get last string in street names. It usually gives street types.\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# List of Valid and Expected Street Types\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Plaza\", \"Turnpike\", \"Alley\", \"Walk\", \"Way\", \"Terrace\" ]\n",
    "\n",
    "# Function to check if its tag is for street name\n",
    "def is_street_name(elem):\n",
    "        return (elem.attrib['k'] == \"addr:street\")\n",
    "    \n",
    "# Fuction to find out different street types which are not in expected list of street types\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "# Function to parse the map osm file and call audit_street_type function. This will return dict \n",
    "#of different street types and their occurances\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\", encoding=\"utf-8\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types\n",
    "\n",
    "street_types = audit(filename)\n",
    "pprint.pprint(street_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed there are a lot of inconsistencies, like for Streets I has below types:\n",
    "'St','St.','Steet','Streeet','st','street', 'ST'\n",
    "There are few typos and some abbreviations.\n",
    "\n",
    "Samething, I noticed about Avenues, Boulevard, Plaza.\n",
    "In first iteration, Plaza,Turnpike, Walk, Way were not included in expected list. I added them in expected list in next iterations and reran above audit script.\n",
    "By resolving these inconsistencies I will make my data more uniform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preparing for Database\n",
    "\n",
    "I will load JC OSM XML dataset to MongoDB database for further analysis. To load to MongoDB I will convert XML OSM file to JSON file. I have selected below datamodel for my database.\n",
    "```javascript\n",
    "{  \n",
    "\"id\": \"2406124091\",  \n",
    "\"type: \"node\",  \n",
    "\"visible\":\"true\",  \n",
    "\"created\": {  \n",
    "          \"version\":\"2\",  \n",
    "          \"changeset\":\"17206049\",  \n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",  \n",
    "          \"user\":\"linuxUser16\",  \n",
    "          \"uid\":\"1219059\"  \n",
    "        },  \n",
    "\"pos\": [41.9757030, -87.6921867],  \n",
    "\"address\": {  \n",
    "          \"housenumber\": \"5157\",  \n",
    "          \"postcode\": \"60625\",  \n",
    "          \"street\": \"North Lincoln Ave\"  \n",
    "        },  \n",
    "\"amenity\": \"restaurant\",  \n",
    "\"cuisine\": \"mexican\",  \n",
    "\"name\": \"La Cabana De Don Luis\",  \n",
    "\"phone\": \"1 (773)-271-5176\"  \n",
    "}  \n",
    "```\n",
    "\n",
    "I will get all metadata details about the node or ways entry under \"created\" key. Latitude and Longitude are included under \"pos\". As discussed before all address related details will be included under \"address\".\n",
    "\n",
    "Below rules will be followed to model and transform the data:\n",
    "\n",
    "* Only \"node\" and \"way\" - 2 top level tags will be processed.\n",
    "* All attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "    * attributes in the CREATED array should be added under a key \"created\"\n",
    "    CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "    * attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings.\n",
    "* if second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "* if second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "* if second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it same as any other tag.\n",
    "* if there is a second \":\" that separates the type/direction of a street, the tag should be ignored, for example:\n",
    "\n",
    "```xml\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "```\n",
    "  should be turned into:\n",
    "\n",
    "``` javascript\n",
    "{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}\n",
    "```\n",
    "\n",
    "* for \"way\" specifically:\n",
    "```xml\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "```\n",
    "\n",
    "should be turned into\n",
    "```javascript\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "```\n",
    "\n",
    "Below are code snippets to convert street names to consistent names (identified in above section). And then shape the data in the required format. \n",
    "\n",
    "First, I will write update_name function to change street_names to better names.\n",
    "I will define mapping between inconsistent and better street types in mapping dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th St. => 9th Street\n",
      "West 44th St. => West 44th Street\n",
      "E. 54th St. => E. 54th Street\n",
      "East 73rd St. => East 73rd Street\n",
      "East 86th St. => East 86th Street\n",
      "Devoe St. => Devoe Street\n",
      "Henry St. => Henry Street\n",
      "South 4th St. => South 4th Street\n",
      "Washington St. => Washington Street\n",
      "11th St. => 11th Street\n",
      "Warren St. => Warren Street\n",
      "South 4th st => South 4th Street\n",
      "W 35th st => W 35th Street\n",
      "Union st => Union Street\n",
      "Johnson Streeet => Johnson Street\n",
      "3rd St => 3rd Street\n",
      "Bloomfield St => Bloomfield Street\n",
      "6th St => 6th Street\n",
      "Hudson St => Hudson Street\n",
      "1st St => 1st Street\n",
      "40 W 94th St => 40 W 94th Street\n",
      "Adams St => Adams Street\n",
      "Grand St => Grand Street\n",
      "Smith St & Bergen St => Smith Street & Bergen Street\n",
      "8th St => 8th Street\n",
      "2nd St => 2nd Street\n",
      "Garden St => Garden Street\n",
      "Jackson St => Jackson Street\n",
      "Washington St => Washington Street\n",
      "West 32nd St => West 32nd Street\n",
      "7th St => 7th Street\n",
      "Court St => Court Street\n",
      "Monroe St => Monroe Street\n",
      "362nd Grand St => 362nd Grand Street\n",
      "Jefferson St => Jefferson Street\n",
      "9th St => 9th Street\n",
      "Madison St => Madison Street\n",
      "330 E 84th St => 330 E 84th Street\n",
      "N 7th St => N 7th Street\n",
      "4th St => 4th Street\n",
      "Newark St => Newark Street\n",
      "River St => River Street\n",
      "Clinton St => Clinton Street\n",
      "64th St and 5th Ave => 64th St and 5th Avenue\n",
      "5th Ave => 5th Avenue\n",
      " Westminster Ave =>  Westminster Avenue\n",
      "Hudson Ave => Hudson Avenue\n",
      "Park Ave => Park Avenue\n",
      "4th Ave => 4th Avenue\n",
      "6th Ave => 6th Avenue\n",
      "Third Ave => Third Avenue\n",
      "Willow Ave => Willow Avenue\n",
      "Norman Ave => Norman Avenue\n",
      "Union street => Union Street\n",
      "W. 44th street => W. 44th Street\n",
      "West 57th street => West 57th Street\n",
      "5th street => 5th Street\n",
      "west 55th street => west 55th Street\n",
      "Steinway street => Steinway Street\n",
      "Columbia street => Columbia Street\n",
      "West 51st street => West 51st Street\n",
      "Rivington street => Rivington Street\n",
      "Hudson street => Hudson Street\n",
      "E 45th street => E 45th Street\n",
      "Lafayette street => Lafayette Street\n",
      "East 5th street => East 5th Street\n",
      "Mott street => Mott Street\n",
      "2nd avenue => 2nd Avenue\n",
      "Bedford avenue => Bedford Avenue\n",
      "Utica avenue => Utica Avenue\n",
      "43rd Rd => 43rd Road\n",
      "West 8th Steet => West 8th Street\n",
      "6th ave => 6th Avenue\n",
      "5th ave => 5th Avenue\n",
      "University Plz => University Plaza\n",
      "N 9th ST => N 9th Street\n"
     ]
    }
   ],
   "source": [
    "# dictionary to store mapping between inconsistent and better street types\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Streeet\" : \"Street\",\n",
    "            \"street\" : \"Street\",\n",
    "            \"ST\" : \"Street\",\n",
    "            \"st\" : \"Street\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"ave\" : \"Avenue\",\n",
    "            \"avenue\" : \"Avenue\",\n",
    "            \"PKWY\" : \"Parkway\",\n",
    "            \"Pl\" : \"Place\",\n",
    "            \"Plz\" : \"Plaza\"\n",
    "            }\n",
    "\n",
    "# function accept street name, then do lookup to mapping dict and return updated better street name\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        try:\n",
    "            new_street_type = mapping[street_type]\n",
    "            name = name.replace(street_type, new_street_type)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    return name\n",
    "\n",
    "# Running test to make sure street names are getting updated as expected\n",
    "for st_type, ways in street_types.items():\n",
    "    if st_type in mapping:\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print(name, \"=>\", better_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is shape_element function to transform data in required dictionary format. shape_element uses update_name function to translate street names to better names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list contains all elements which will be included to \"created\" key\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    '''\n",
    "    this function converts osm elements to node dictionary. It will format all attributes \n",
    "    and sub-elements in required model defined above section.\n",
    "    '''\n",
    "    node = {} # return dict with nodes and ways data in our data model format\n",
    "    created = {} # temp dict to store \"created\" key, this will be added to node dict\n",
    "    pos = [None, None] # temp list to store lat and log, this will be added to node dict\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :  # process only \"node\" and \"way\"\n",
    "        # store element type\n",
    "        node[\"type\"] = element.tag \n",
    "        \n",
    "        # loop through element's attributes\n",
    "        for at in element.attrib:\n",
    "            \n",
    "            # all elements in CREATED list will be grouped and stored under created key\n",
    "            if at in CREATED:\n",
    "                created[at] = element.attrib[at]\n",
    "                node[\"created\"] = created\n",
    "            \n",
    "            # store latitudes and longitudes in pos key\n",
    "            elif at in ['lat','lon']:\n",
    "                if at == \"lat\":\n",
    "                    pos[0] = float(element.attrib[at])\n",
    "                else:\n",
    "                    pos[1] = float(element.attrib[at])\n",
    "            else:\n",
    "                node[at] = element.attrib[at]\n",
    "\n",
    "        if not None in pos:\n",
    "            node[\"pos\"] = pos\n",
    "        \n",
    "        # processing inner \"tag\" element for nodes and ways\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if not problemchars.search(tag.attrib[\"k\"]): # filetering problem chars\n",
    "                \n",
    "                # selecting tags starting with \"attrib:\" to get all \"address\" key fields\n",
    "                if lower_colon.search(tag.attrib[\"k\"]) and tag.attrib[\"k\"].startswith(\"addr:\"):\n",
    "                    if \"address\" not in node:\n",
    "                        node[\"address\"] = {}\n",
    "                            \n",
    "                    key = tag.attrib[\"k\"].split(\":\")[1]\n",
    "                    if is_street_name(tag):\n",
    "                        better_name = update_name(tag.attrib[\"v\"], mapping)\n",
    "                        node[\"address\"][key] = better_name\n",
    "                    else:\n",
    "                        node[\"address\"][key] = tag.attrib[\"v\"]\n",
    "                        \n",
    "                # store all other \"tag\" as normal name-value pair\n",
    "                elif lower_colon.search(tag.attrib[\"k\"]) and not tag.attrib[\"k\"].startswith(\"addr:\"):\n",
    "                    node[tag.attrib[\"k\"]] = tag.attrib[\"v\"]\n",
    "        \n",
    "        # to store nd elements under \"node_refs\" list for ways\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            if \"node_refs\" not in node:\n",
    "                node[\"node_refs\"] = []\n",
    "            node[\"node_refs\"].append(nd.attrib[\"ref\"])\n",
    "            \n",
    "        #pprint.pprint(node)\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    '''\n",
    "    This function gets osm file as input, parses the file and then using shape_element\n",
    "    function transforms data in required format. Then write data to JSON file.\n",
    "    '''\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call process map function, passing jersey_city.osm file as input.\n",
    "process_map(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outfile file : jersey_city.osm.json is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Data Overview\n",
    "\n",
    "In this section I have included few statistics of the data. Showed process to load data to MongoDB.\n",
    "Then run some MongoDB queries to get more information regarding data.\n",
    "\n",
    "### File Sizes\n",
    "Size of the original XML OSM file downloaded for Jersey City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the downloaded OSM file - jersey_city.osm: 474.760615 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "osm_file_size = os.path.getsize(filename)/1.0e6\n",
    "print(\"Size of the downloaded OSM file - {}: {} MB\".format(filename, osm_file_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the created JSON file - jersey_city.osm.json: 486.374754 MB\n"
     ]
    }
   ],
   "source": [
    "output_filename = filename +\".json\"\n",
    "json_file_size = os.path.getsize(output_filename)/1.0e6\n",
    "print(\"Size of the created JSON file - {}: {} MB\".format(output_filename, json_file_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data to MongoDB\n",
    "Now we will load jersey_city.osm.json to MongoDB.\n",
    "MongoDB instance is running locally in my machine. I will use pyMongo to connect with MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client.osm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "osm db is created. To load json file to MongoDB, I used *mongoimport* utility. I will call this mongoimport utility from command line and load data to database. I can easily script this step using python or shell scripts. \n",
    "\n",
    "mongoimport takes 3 arguments : \n",
    "db : database name -> osm\n",
    "collection : collection name -> jersey_city\n",
    "file : json format file -> jersey_city.osm.json\n",
    "\n",
    "Below is snippet output of my import:\n",
    "\n",
    "```bash\n",
    "C:\\Program Files\\MongoDB\\Server\\3.0\\bin>mongoimport --db \"osm\" --collection \"jersey_city\" --file \"C:\\Users\\Prashant\\Dropbox\\Udacity\\Data_Analyst_ND\\jersey_city.osm.json\"\n",
    "2015-08-30T18:02:21.207-0400    connected to: localhost\n",
    "2015-08-30T18:02:24.177-0400    [........................] osm.jersey_city      16.2 MB/463.8 MB (3.5%)\n",
    "2015-08-30T18:02:27.151-0400    [#.......................] osm.jersey_city      36.4 MB/463.8 MB (7.8%)\n",
    "2015-08-30T18:02:30.151-0400    [##......................] osm.jersey_city      56.8 MB/463.8 MB (12.2%)\n",
    "2015-08-30T18:02:33.153-0400    [####....................] osm.jersey_city      78.1 MB/463.8 MB (16.8%)\n",
    "2015-08-30T18:02:36.151-0400    [#####...................] osm.jersey_city      99.6 MB/463.8 MB (21.5%)\n",
    "2015-08-30T18:02:39.151-0400    [######..................] osm.jersey_city      118.1 MB/463.8 MB (25.5%)\n",
    "2015-08-30T18:02:42.152-0400    [#######.................] osm.jersey_city      136.4 MB/463.8 MB (29.4%)\n",
    "2015-08-30T18:02:45.151-0400    [########................] osm.jersey_city      156.5 MB/463.8 MB (33.7%)\n",
    "2015-08-30T18:02:48.151-0400    [#########...............] osm.jersey_city      176.7 MB/463.8 MB (38.1%)\n",
    "2015-08-30T18:02:51.154-0400    [##########..............] osm.jersey_city      194.9 MB/463.8 MB (42.0%)\n",
    "2015-08-30T18:02:54.151-0400    [##########..............] osm.jersey_city      212.5 MB/463.8 MB (45.8%)\n",
    "2015-08-30T18:02:57.154-0400    [############............] osm.jersey_city      232.8 MB/463.8 MB (50.2%)\n",
    "2015-08-30T18:03:00.156-0400    [#############...........] osm.jersey_city      253.0 MB/463.8 MB (54.5%)\n",
    "2015-08-30T18:03:03.151-0400    [##############..........] osm.jersey_city      273.1 MB/463.8 MB (58.9%)\n",
    "2015-08-30T18:03:06.151-0400    [###############.........] osm.jersey_city      291.6 MB/463.8 MB (62.9%)\n",
    "2015-08-30T18:03:09.152-0400    [################........] osm.jersey_city      311.8 MB/463.8 MB (67.2%)\n",
    "2015-08-30T18:03:12.151-0400    [#################.......] osm.jersey_city      331.1 MB/463.8 MB (71.4%)\n",
    "2015-08-30T18:03:15.151-0400    [##################......] osm.jersey_city      350.5 MB/463.8 MB (75.6%)\n",
    "2015-08-30T18:03:18.157-0400    [###################.....] osm.jersey_city      370.4 MB/463.8 MB (79.9%)\n",
    "2015-08-30T18:03:21.153-0400    [####################....] osm.jersey_city      394.5 MB/463.8 MB (85.0%)\n",
    "2015-08-30T18:03:24.151-0400    [#####################...] osm.jersey_city      418.4 MB/463.8 MB (90.2%)\n",
    "2015-08-30T18:03:27.152-0400    [#######################.] osm.jersey_city      444.8 MB/463.8 MB (95.9%)\n",
    "2015-08-30T18:03:29.561-0400    imported 2033581 documents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I ran few queries on jersey_city collections to gather some stats and information on data.\n",
    "\n",
    "#### Number of Documents in Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033581"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1721029"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"node\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.jersey_city.distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'Rub21_nycbuildings', 'count': 1073036},\n",
       " {'_id': 'lxbarth_nycbuildings', 'count': 135794},\n",
       " {'_id': 'ediyes_nycbuildings', 'count': 112386},\n",
       " {'_id': 'ingalls_nycbuildings', 'count': 108182},\n",
       " {'_id': 'celosia_nycbuildings', 'count': 81625}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{ \"$group\" : {\"_id\" : \"$created.user\", \"count\" : {\"$sum\" : 1}}},\n",
    "        {\"$sort\" : {\"count\" : -1}}, \n",
    "        {\"$limit\" : 5} \n",
    "        ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Zip Codes Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '11203', 'count': 11773},\n",
       " {'_id': '11215', 'count': 9533},\n",
       " {'_id': '11221', 'count': 9402},\n",
       " {'_id': '11236', 'count': 8797},\n",
       " {'_id': '11220', 'count': 8612},\n",
       " {'_id': '11377', 'count': 8374},\n",
       " {'_id': '11385', 'count': 8282},\n",
       " {'_id': '11233', 'count': 8015},\n",
       " {'_id': '11218', 'count': 6880},\n",
       " {'_id': '11212', 'count': 6751},\n",
       " {'_id': '11216', 'count': 6381},\n",
       " {'_id': '11211', 'count': 6339},\n",
       " {'_id': '11226', 'count': 6140},\n",
       " {'_id': '11222', 'count': 6102},\n",
       " {'_id': '11105', 'count': 5949},\n",
       " {'_id': '11378', 'count': 5675},\n",
       " {'_id': '11206', 'count': 5467},\n",
       " {'_id': '11213', 'count': 5315},\n",
       " {'_id': '11231', 'count': 4881},\n",
       " {'_id': '11103', 'count': 4761},\n",
       " {'_id': '11238', 'count': 4691},\n",
       " {'_id': '11237', 'count': 4565},\n",
       " {'_id': '11217', 'count': 4509},\n",
       " {'_id': '11207', 'count': 4505},\n",
       " {'_id': '11101', 'count': 4148},\n",
       " {'_id': '11225', 'count': 4099},\n",
       " {'_id': '11219', 'count': 3946},\n",
       " {'_id': '11201', 'count': 3944},\n",
       " {'_id': '10301', 'count': 3674},\n",
       " {'_id': '11106', 'count': 3592},\n",
       " {'_id': '11205', 'count': 3243},\n",
       " {'_id': '11232', 'count': 3214},\n",
       " {'_id': '11102', 'count': 3067},\n",
       " {'_id': '10011', 'count': 2772},\n",
       " {'_id': '10014', 'count': 2522},\n",
       " {'_id': '10003', 'count': 2482},\n",
       " {'_id': '10002', 'count': 2421},\n",
       " {'_id': '10024', 'count': 2404},\n",
       " {'_id': '10013', 'count': 2125},\n",
       " {'_id': '10310', 'count': 2043},\n",
       " {'_id': '11104', 'count': 2042},\n",
       " {'_id': '11249', 'count': 2005},\n",
       " {'_id': '10303', 'count': 1888},\n",
       " {'_id': '10016', 'count': 1872},\n",
       " {'_id': '11210', 'count': 1844},\n",
       " {'_id': '10019', 'count': 1772},\n",
       " {'_id': '10021', 'count': 1708},\n",
       " {'_id': '10065', 'count': 1705},\n",
       " {'_id': '10128', 'count': 1688},\n",
       " {'_id': '10023', 'count': 1687},\n",
       " {'_id': '10028', 'count': 1684},\n",
       " {'_id': '10029', 'count': 1680},\n",
       " {'_id': '10009', 'count': 1629},\n",
       " {'_id': '10001', 'count': 1609},\n",
       " {'_id': '10022', 'count': 1564},\n",
       " {'_id': '10012', 'count': 1521},\n",
       " {'_id': '10036', 'count': 1395},\n",
       " {'_id': '10302', 'count': 1290},\n",
       " {'_id': '11370', 'count': 1018},\n",
       " {'_id': '10018', 'count': 935},\n",
       " {'_id': '10025', 'count': 906},\n",
       " {'_id': '11209', 'count': 905},\n",
       " {'_id': '10017', 'count': 902},\n",
       " {'_id': '10010', 'count': 879},\n",
       " {'_id': '10075', 'count': 797},\n",
       " {'_id': '11234', 'count': 705},\n",
       " {'_id': '10038', 'count': 629},\n",
       " {'_id': '11379', 'count': 532},\n",
       " {'_id': '10004', 'count': 372},\n",
       " {'_id': '10007', 'count': 341},\n",
       " {'_id': '11372', 'count': 242},\n",
       " {'_id': '11230', 'count': 197},\n",
       " {'_id': '10005', 'count': 196},\n",
       " {'_id': '10035', 'count': 167},\n",
       " {'_id': '10006', 'count': 125},\n",
       " {'_id': '07302', 'count': 61},\n",
       " {'_id': '10020', 'count': 55},\n",
       " {'_id': '10044', 'count': 55},\n",
       " {'_id': '11204', 'count': 52},\n",
       " {'_id': '10280', 'count': 37},\n",
       " {'_id': '10282', 'count': 35},\n",
       " {'_id': '10069', 'count': 32},\n",
       " {'_id': '10304', 'count': 22},\n",
       " {'_id': '07306', 'count': 19},\n",
       " {'_id': '07030', 'count': 17},\n",
       " {'_id': '11109', 'count': 14},\n",
       " {'_id': '07050', 'count': 11},\n",
       " {'_id': '07087', 'count': 11},\n",
       " {'_id': '10281', 'count': 9},\n",
       " {'_id': '10111', 'count': 6},\n",
       " {'_id': '07111', 'count': 6},\n",
       " {'_id': '07086', 'count': 6},\n",
       " {'_id': '07104', 'count': 5},\n",
       " {'_id': '10048', 'count': 4},\n",
       " {'_id': '07202', 'count': 4},\n",
       " {'_id': '10055', 'count': 3},\n",
       " {'_id': '07003', 'count': 3},\n",
       " {'_id': '07208', 'count': 3},\n",
       " {'_id': '10154', 'count': 3},\n",
       " {'_id': '10152', 'count': 3},\n",
       " {'_id': '11251', 'count': 3},\n",
       " {'_id': '07201', 'count': 3},\n",
       " {'_id': '07093', 'count': 3},\n",
       " {'_id': '07114', 'count': 2},\n",
       " {'_id': '10275', 'count': 2},\n",
       " {'_id': '10153', 'count': 2},\n",
       " {'_id': 'NY 10075', 'count': 2},\n",
       " {'_id': '07311', 'count': 2},\n",
       " {'_id': '07102', 'count': 2},\n",
       " {'_id': '07105', 'count': 2},\n",
       " {'_id': '07304', 'count': 2},\n",
       " {'_id': '07047', 'count': 1},\n",
       " {'_id': '10002-1013', 'count': 1},\n",
       " {'_id': 'New York, NY 10065', 'count': 1},\n",
       " {'_id': '83', 'count': 1},\n",
       " {'_id': '10018-3883', 'count': 1},\n",
       " {'_id': '11224', 'count': 1},\n",
       " {'_id': '10001-2062', 'count': 1},\n",
       " {'_id': '11232-2400', 'count': 1},\n",
       " {'_id': '11231;11230', 'count': 1},\n",
       " {'_id': '11201;11231', 'count': 1},\n",
       " {'_id': '11215-9993', 'count': 1},\n",
       " {'_id': '07032', 'count': 1},\n",
       " {'_id': '07107', 'count': 1},\n",
       " {'_id': '07206', 'count': 1},\n",
       " {'_id': '07031', 'count': 1},\n",
       " {'_id': '11361', 'count': 1},\n",
       " {'_id': 'NY 11106', 'count': 1},\n",
       " {'_id': '07305-9997', 'count': 1},\n",
       " {'_id': '10012-3332', 'count': 1},\n",
       " {'_id': '07310', 'count': 1},\n",
       " {'_id': '10121', 'count': 1},\n",
       " {'_id': '10169', 'count': 1},\n",
       " {'_id': '10016-0122', 'count': 1},\n",
       " {'_id': '10174', 'count': 1},\n",
       " {'_id': 'NJ 07105', 'count': 1},\n",
       " {'_id': 'NY 10111', 'count': 1},\n",
       " {'_id': 'NY 10002', 'count': 1},\n",
       " {'_id': '11201-2483', 'count': 1},\n",
       " {'_id': '07036', 'count': 1},\n",
       " {'_id': 'NY 11201', 'count': 1},\n",
       " {'_id': '10123', 'count': 1},\n",
       " {'_id': '07096', 'count': 1},\n",
       " {'_id': '07030-5774', 'count': 1},\n",
       " {'_id': ' 07310', 'count': 1},\n",
       " {'_id': '07002', 'count': 1},\n",
       " {'_id': '10168', 'count': 1},\n",
       " {'_id': '10155', 'count': 1},\n",
       " {'_id': '10018-4527', 'count': 1},\n",
       " {'_id': '07207', 'count': 1},\n",
       " {'_id': 'NY 11221', 'count': 1},\n",
       " {'_id': '10011-6832', 'count': 1}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{ \"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$match\" : {\"_id\" : {\"$ne\" : None}}},\n",
    "                          {\"$sort\" : {\"count\" : -1}}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Jersey City Zip Codes\n",
    "I noticed that the coverage of only jersey city zipcodes is very limited in OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '07302', 'count': 61},\n",
       " {'_id': '07306', 'count': 19},\n",
       " {'_id': '07311', 'count': 2},\n",
       " {'_id': '07304', 'count': 2},\n",
       " {'_id': '07310', 'count': 1}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get counts of Only list of Jersey City Zip Codes.\n",
    "db.jersey_city.aggregate([{\"$match\" : {\"address.postcode\" : {\"$in\" : [\"07097\",\"07302\",\"07303\",\"07304\",\"07305\",\"07306\",\"07307\",\"07308\",\"07310\",\"07311\"]} }},\n",
    "                          {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$sort\" : {\"count\" : -1}}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Cities\n",
    "All cities in my selected area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'New York', 'count': 3733},\n",
       " {'_id': 'Brooklyn', 'count': 965},\n",
       " {'_id': 'Hoboken', 'count': 504},\n",
       " {'_id': 'New York City', 'count': 127},\n",
       " {'_id': 'Jersey City', 'count': 73},\n",
       " {'_id': 'Astoria', 'count': 69},\n",
       " {'_id': 'Long Island City', 'count': 34},\n",
       " {'_id': 'Newark', 'count': 33},\n",
       " {'_id': 'Sunnyside', 'count': 11},\n",
       " {'_id': 'Orange', 'count': 11},\n",
       " {'_id': 'Union City', 'count': 10},\n",
       " {'_id': 'Elizabeth', 'count': 9},\n",
       " {'_id': 'Staten Island', 'count': 8},\n",
       " {'_id': 'Woodside', 'count': 8},\n",
       " {'_id': 'brooklyn', 'count': 7},\n",
       " {'_id': 'New York, NY', 'count': 6},\n",
       " {'_id': 'Queens', 'count': 6},\n",
       " {'_id': 'Weehawken', 'count': 6},\n",
       " {'_id': 'Brooklyn, NY', 'count': 5},\n",
       " {'_id': 'Ridgewood', 'count': 4},\n",
       " {'_id': 'West New York', 'count': 4},\n",
       " {'_id': 'Bloomfield', 'count': 3},\n",
       " {'_id': 'NEW YORK CITY', 'count': 3},\n",
       " {'_id': 'North Bergen', 'count': 2},\n",
       " {'_id': 'North Arlington', 'count': 1},\n",
       " {'_id': 'newark', 'count': 1},\n",
       " {'_id': 'New York NY', 'count': 1},\n",
       " {'_id': 'Waterbury', 'count': 1},\n",
       " {'_id': 'Bowery Bay, NY', 'count': 1},\n",
       " {'_id': 'M', 'count': 1},\n",
       " {'_id': 'Roosevelt Island', 'count': 1},\n",
       " {'_id': 'new york', 'count': 1},\n",
       " {'_id': 'new York', 'count': 1},\n",
       " {'_id': 'Queens, NY', 'count': 1},\n",
       " {'_id': 'NY', 'count': 1},\n",
       " {'_id': 'Manhattan', 'count': 1},\n",
       " {'_id': 'Middle Village', 'count': 1},\n",
       " {'_id': 'Manhattan NYC', 'count': 1},\n",
       " {'_id': 'Brooklyn, New York', 'count': 1},\n",
       " {'_id': 'end of pier', 'count': 1},\n",
       " {'_id': 'Glendale', 'count': 1},\n",
       " {'_id': 'elizabeth', 'count': 1},\n",
       " {'_id': 'New York city', 'count': 1},\n",
       " {'_id': 'Blissville', 'count': 1},\n",
       " {'_id': 'NEWARK', 'count': 1},\n",
       " {'_id': 'Kearny', 'count': 1}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{\"$group\" : {\"_id\" : \"$address.city\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$match\" : {\"_id\" : {\"$ne\" : None}}},\n",
    "                          {\"$sort\" : {\"count\" : -1}}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Additional Ideas\n",
    "\n",
    "### nycbuildings\n",
    "\n",
    "In previous section, I found that top 5 users are all following some pattern of \"nycbuildings\"\n",
    "I reserached more on this, looks like as part of NYC open data initiative last year bulk of this data were loaded to OSM.\n",
    "\n",
    "Below article contain detail on this:\n",
    "https://www.mapbox.com/blog/nyc-buildings-openstreetmap/\n",
    "\n",
    "After querying using mongodb regex, I found that 78% of this dataset is from nycbuilding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596652"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find( {\"created.user\" : {\"$regex\" : \"nycbuildings$\" } } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These nycbuildings documents doesnt have many useful information. Only few of them have address. All other useful attributes like amenities etc are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230417"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find( {\"created.user\" : {\"$regex\" : \"nycbuildings$\" }, \"address\" : {\"$exists\" : 1} } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents for TIGER and GNIS\n",
    "\n",
    "After looking more into this dataset, the data is filled with many entries for \"way\" from TIGER (Topologically Integrated Geographic Encoding and Referencing system)\n",
    "http://wiki.openstreetmap.org/wiki/TIGER\n",
    "\n",
    "There are also many entries for \"node\" from GNIS (USGS Geographic Names Information System).\n",
    "http://wiki.openstreetmap.org/wiki/USGS_GNIS\n",
    "\n",
    "As per documentation of both of these above sources (datasets), data seems outdated or incorrect.\n",
    "GNIS:ID suppose to map with OSM amenity tags, but no corresponding amenity tags are present for these GNIS:ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17388"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way document from tiger\n",
    "db.jersey_city.find( { \"type\" : \"way\", \"tiger:cfcc\" : { \"$exists\": 1 } } ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2117"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node documents from gnis\n",
    "db.jersey_city.find( { \"type\" : \"node\", \"gnis:created\" : { \"$exists\": 1 } } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Node and Way with Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54045"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"node\", \"address.street\" : {\"$exists\" : 1}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200005"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"way\", \"address.street\" : {\"$exists\" : 1}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to presence of nycbuildings, tiger and gnis incomplete data, my dataset is not giving much useful information.\n",
    "Below are important ideas which are important to make this OSM data more useful:\n",
    "\n",
    "* Cleaning up invalid and outdated data from TIGER and GNIS.\n",
    "* Mappings valid TIGER/GNIS data keys/attributes with OSM keys/attributes.\n",
    "* Adding more information and attributes to nycbuildings data.\n",
    "* Attracting more users and developers to OSM.\n",
    "\n",
    "### Conclusion\n",
    "Jersey City and the neighbouring areas data needs cleaning and mapping. NYCBuidlings data has created a nice skeleton, which can be leveraged to make this data more useful.\n",
    "In current state, it is difficult to gain any intelligence from this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
