{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangle OpenStreetMap Data\n",
    "\n",
    "Map Area: Jersey City, New Jersey, USA\n",
    "\n",
    "Map links for Jersey City     \n",
    "https://www.openstreetmap.org/relation/170953    \n",
    "http://overpass-api.de/api/map?bbox=-74.2432,40.6343,-73.8944,40.7961\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "OpenStreepMap is a collaborative project to create free editable map of the world. Its similar to Wikipedia in sourcing data.\n",
    "Data from OSM can be exported in XML format (.osm). This data can be analyzed and used in different projects. Data is availabe under Open Database License.\n",
    "\n",
    "More details regarding OSM and .osm data format can be found below:\n",
    "https://en.wikipedia.org/wiki/OpenStreetMap\n",
    "http://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "\n",
    "### Map Area\n",
    "\n",
    "In this project, I will be analyzing selected map area (Jersey City, NJ) data quality (DQ) for validity, accuracy, consistency and uniformity. I will be wrangling xml format of data using Python. After some DQ checks and cleaning some data, I will be storing data to MongoDB. Then I will be performing some queries and data aggregations to get some information about data.\n",
    "\n",
    "I selected Jersey city (JC), because its my current work location. Jersey City is most ethnically diverse cities in the world and fourth most densely populated city in the United States. It is part of New York Metropolitan area also.\n",
    "I tried downloading JC data from openstreetmap export option, but it failed. Then I decided to use overpass-api to download data. I am using Python HTTP library - Requests to get the data.\n",
    "\n",
    "Below code will download Jersey City map data in jersey_city.osm file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# overpass url for jersey city, nj\n",
    "url = 'http://overpass-api.de/api/map?bbox=-74.2432,40.6343,-73.8944,40.7961'\n",
    "filename = 'jersey_city.osm'\n",
    "\n",
    "\n",
    "def download_osm(url, filename):\n",
    "    r = requests.get(url, stream = True) # http get to download the data\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "download_osm(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am including below map area to show the area covered in analysis. When I got the co-ordinate range for jersey city from openstreetmap, I did not realize it was not exactly for Jersey City, but it covered many neighbouring areas. By the time I realized it, I was very further in project, so I decided to continue and use these co-ordinates as my area of interest.  Please note, Jersey City term in this project will include Jersey City and other areas in these co-ordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"425\" height=\"350\" frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" src=\"http://www.openstreetmap.org/export/embed.html?bbox=-74.25212860107422%2C40.64730356252251%2C-73.98914337158203%2C40.809131953785965&amp;layer=mapnik\" style=\"border: 1px solid black\"></iframe><br/><small><a href=\"http://www.openstreetmap.org/#map=12/40.7283/-74.1206\">View Larger Map</a></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<iframe width=\"425\" height=\"350\" frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" src=\"http://www.openstreetmap.org/export/embed.html?bbox=-74.25212860107422%2C40.64730356252251%2C-73.98914337158203%2C40.809131953785965&amp;layer=mapnik\" style=\"border: 1px solid black\"></iframe><br/><small><a href=\"http://www.openstreetmap.org/#map=12/40.7283/-74.1206\">View Larger Map</a></small>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Problems Encountered in the Map\n",
    "In this section, I will parse osm map file. Talk about different problem with data and fixing it.\n",
    "Finally, preparing the data for Mongodb load.\n",
    "\n",
    "### Map Parsing\n",
    "\n",
    "I will parse osm file using ElementTree to find out different tags present in the file. Keeping the size of the file in the mind, I will use SAX parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 84098,\n",
      " 'meta': 1,\n",
      " 'nd': 2457737,\n",
      " 'node': 1721029,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 2450,\n",
      " 'tag': 2000510,\n",
      " 'way': 312552}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    osm_file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "    \n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(filename)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 1.7 millions nodes defined. Also, big number of ways are defined.\n",
    "There are 2000510 tags present in the file. These tags are name-value pair, to define multiple attributes of nodes or ways.\n",
    "\n",
    "Also, for my final data model for MongoDB, I will be grouping similar tags (like address). I will further audit tags to find some pattern and to remove problematic/invalid data for MongoDB. I will try to make sure if these values can be valid keys for MongoDB.\n",
    "\n",
    "I am using Python regular expression to perform this auditing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 742444,\n",
      " 'lower_colon': 1222919,\n",
      " 'other': 15181,\n",
      " 'problemchars': 19966}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# define regular expressions\n",
    "lower = re.compile(r'^([a-z]|_)*$') # reg-ex for lower case\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$') # reg-ex for lower case and presence of colon (:)\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]') # reg-ex for probelm chars not allowed for MongoDB keys\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.search(element.attrib[\"k\"]):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map(filename)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19966 tags with problem characters which can cause issue while loading to MongoDB.\n",
    "With some further exploring, I can find tags with keys : \"addr:\"\n",
    "I will be grouping by \"addr:\" under \"address\" key in data model. lower_colon will help to find these keys.\n",
    "\n",
    "I will do more exploring of data, this time to find out about users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Users: 1556\n"
     ]
    }
   ],
   "source": [
    "def get_user(element, user):\n",
    "    user = \"\"\n",
    "    at = element.attrib\n",
    "    \n",
    "    for key in at:\n",
    "        if key == \"user\" and at[\"user\"] != \"\":\n",
    "            user = at[\"user\"]\n",
    "    return user\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user = get_user(element, users)\n",
    "        if user != \"\":\n",
    "            users.add(user)\n",
    "    return users \n",
    "\n",
    "users = process_map(filename)\n",
    "print(\"Number of Unique Users: {}\".format(len(users))) # Getting number of Unique Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent Street Names\n",
    "Street Names present in this map data is inconsistent. Since data is crowd sourced, there is no standard in mentioning street names and addresses. Many street names are over abbreviated.\n",
    "In first problem finding exercise I will try to find such inconsistencies in street names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# RegEx to get last string in street names. It usually gives street types.\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# List of Valid and Expected Street Types\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Plaza\", \"Turnpike\", \"Alley\", \"Walk\", \"Way\", \"Terrace\" ]\n",
    "\n",
    "# Function to check if its tag is for street name\n",
    "def is_street_name(elem):\n",
    "        return (elem.attrib['k'] == \"addr:street\")\n",
    "    \n",
    "# Fuction to find out different street types which are not in expected list of street types\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "# Function to parse the map osm file and call audit_street_type function. This will return dict \n",
    "#of different street types and their occurances\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\", encoding=\"utf-8\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types\n",
    "\n",
    "street_types = audit(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below examples of above code snippet output\n",
    "```javascript\n",
    "\"Ave\" {\" Westminster Ave\",\n",
    "         \"4th Ave\",\n",
    "         \"5th Ave\",\n",
    "         \"64th St and 5th Ave\",\n",
    "         \"6th Ave\",\n",
    "         \"Hudson Ave\",\n",
    "         \"Norman Ave\",\n",
    "         \"Park Ave\",\n",
    "         \"Third Ave\",\n",
    "         \"Willow Ave\"}\n",
    " \"Ave\" {\"Springfield Ave.\", \"Washington Ave.\"}\n",
    " \"Avene\": {\"Nostrand Avene\", \"Madison Avene\"},\n",
    " \"Blv.\": {\"John F. Kennedy Blv.\"},\n",
    " \"Blvd\": {\"Marin Blvd\", \"Queens Blvd\"},\n",
    " \"Park\": {\"FDR Four Freedoms Park\",\n",
    "          \"Fort Hill Park\",\n",
    "          \"Gramercy Park\",\n",
    "          \"Washington Park\"},\n",
    " \"Piers\": {\"Northside Piers\"},\n",
    " \"Plz\": {\"University Plz\"},\n",
    " \"Rd\": {\"43rd Rd\"},\n",
    " \"St.\": {\"11th St.\",\n",
    "         \"9th St.\",\n",
    "         \"Devoe St.\",\n",
    "         \"E. 54th St.\",\n",
    "         \"East 73rd St.\",\n",
    "         \"East 86th St.\",\n",
    "         \"Henry St.\",\n",
    "         \"South 4th St.\",\n",
    "         \"Warren St.\",\n",
    "         \"Washington St.\",\n",
    "         \"West 44th St.\"},\n",
    " \"Steet\": {\"West 8th Steet\"},\n",
    " \"Streeet\": {\"Johnson Streeet\"}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed there are a lot of inconsistencies, like for Streets I has below types:\n",
    "'St','St.','Steet','Streeet','st','street', 'ST'\n",
    "There are few typos and some abbreviations.\n",
    "\n",
    "Samething, I noticed about Avenues, Boulevard, Plaza.\n",
    "In first iteration, Plaza,Turnpike, Walk, Way were not included in expected list. I added them in expected list in next iterations and reran above audit script.\n",
    "By resolving these inconsistencies I will make my data more uniform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Uniformity in City Names\n",
    "\n",
    "Due to crowd-sourced entries, city names in map data is not conistent. NYC is consist of many big boroughs due to that many places I noticed city name is replaces with neighbourhood names and borough names. Some places city names are misspelled or abbreviated. During my initial load to MongoDB I found below examples:\n",
    "\n",
    "{'Manhattan NYC', 'Brooklyn, New York', 'new York', 'Queens, NY', 'NY', 'Manhattan', 'New York NY', 'Waterbury', 'Bowery Bay',\n",
    " 'NEW YORK CITY'}\n",
    " Above are only few samples, there are few more . Now, I will reload the data and before loading I will cleanup city names to make it inconsistent as possible.\n",
    " \n",
    "Below mapping dictionary is used to map incosistent, incorrect city names to uniform city name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City\n"
     ]
    }
   ],
   "source": [
    "city_mapping = { 'New York' : 'New York City',\n",
    "                'Brooklyn' : 'New York City',\n",
    "                'Astoria' : 'New York City',\n",
    "                'Long Island City' : 'New York City',\n",
    "                'Sunnyside' : 'New York City',\n",
    "                'Staten Island' : 'New York City',\n",
    "                'Woodside' : 'New York City',\n",
    "                'brooklyn' : 'New York City',\n",
    "                'New York, NY' : 'New York City',\n",
    "                'Queens' : 'New York City',\n",
    "                'Brooklyn, NY' : 'New York City',\n",
    "                'Ridgewood' : 'New York City',\n",
    "                'NEW YORK CITY' : 'New York City',\n",
    "                'New York NY' : 'New York City',\n",
    "                'Bowery Bay, NY' : 'New York City',\n",
    "                'Roosevelt Island' : 'New York City',\n",
    "                'new york' : 'New York City',\n",
    "                'new York' : 'New York City',\n",
    "                'Queens, NY' : 'New York City',\n",
    "                'NY' : 'New York City',\n",
    "                'Manhattan' : 'New York City',\n",
    "                'Middle Village' : 'New York City',\n",
    "                'Manhattan NYC' : 'New York City',\n",
    "                'Brooklyn, New York' : 'New York City',\n",
    "                'end of pier' : 'New York City' }\n",
    "\n",
    "# function to verify city name tag\n",
    "def is_city_name(elem):\n",
    "        return (elem.attrib['k'] == \"addr:city\")\n",
    "\n",
    "# Below function will accept city name, after looking up in city_mapping dict, it will return consistent name\n",
    "def update_city(city_name, city_mapping):\n",
    "    if city_name in city_mapping:\n",
    "        updated_city_name = city_mapping[city_name]\n",
    "        return updated_city_name\n",
    "    else:\n",
    "        return city_name\n",
    "\n",
    "#  Test update_city for city name from map data\n",
    "new_city_name = update_city(\"Manhattan\", city_mapping)\n",
    "print(new_city_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preparing for Database\n",
    "\n",
    "I will load JC OSM XML dataset to MongoDB database for further analysis. To load to MongoDB I will convert XML OSM file to JSON file. I have selected below datamodel for my database.\n",
    "```javascript\n",
    "{  \n",
    "\"id\": \"2406124091\",  \n",
    "\"type: \"node\",  \n",
    "\"visible\":\"true\",  \n",
    "\"created\": {  \n",
    "          \"version\":\"2\",  \n",
    "          \"changeset\":\"17206049\",  \n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",  \n",
    "          \"user\":\"linuxUser16\",  \n",
    "          \"uid\":\"1219059\"  \n",
    "        },  \n",
    "\"pos\": [41.9757030, -87.6921867],  \n",
    "\"address\": {  \n",
    "          \"housenumber\": \"5157\",  \n",
    "          \"postcode\": \"60625\",  \n",
    "          \"street\": \"North Lincoln Ave\"  \n",
    "        },  \n",
    "\"amenity\": \"restaurant\",  \n",
    "\"cuisine\": \"mexican\",  \n",
    "\"name\": \"La Cabana De Don Luis\",  \n",
    "\"phone\": \"1 (773)-271-5176\"  \n",
    "}  \n",
    "```\n",
    "\n",
    "I will get all metadata details about the node or ways entry under \"created\" key. Latitude and Longitude are included under \"pos\". As discussed before all address related details will be included under \"address\".\n",
    "\n",
    "Below rules will be followed to model and transform the data:\n",
    "\n",
    "* Only \"node\" and \"way\" - 2 top level tags will be processed.\n",
    "* All attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "    * attributes in the CREATED array should be added under a key \"created\"\n",
    "    CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "    * attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings.\n",
    "* if second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "* if second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "* if second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it same as any other tag.\n",
    "* if there is a second \":\" that separates the type/direction of a street, the tag should be ignored, for example:\n",
    "\n",
    "```xml\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "```\n",
    "  should be turned into:\n",
    "\n",
    "``` javascript\n",
    "{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}\n",
    "```\n",
    "\n",
    "* for \"way\" specifically:\n",
    "```xml\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "```\n",
    "\n",
    "should be turned into\n",
    "```javascript\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "```\n",
    "\n",
    "Below are code snippets to convert street names to consistent names (identified in above section). And then shape the data in the required format. \n",
    "\n",
    "First, I will write update_name function to change street_names to better names.\n",
    "I will define mapping between inconsistent and better street types in mapping dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloomfield St => Bloomfield Street\n",
      "6th St => 6th Street\n",
      "Madison St => Madison Street\n",
      "9th St => 9th Street\n",
      "2nd St => 2nd Street\n",
      "N 9th ST => N 9th Street\n",
      "West 8th Steet => West 8th Street\n",
      "Johnson Streeet => Johnson Street\n",
      "6th Ave => 6th Avenue\n",
      "64th St and 5th Ave => 64th St and 5th Avenue\n",
      "Park Ave => Park Avenue\n",
      " Westminster Ave =>  Westminster Avenue\n",
      "Willow Ave => Willow Avenue\n",
      "Steinway street => Steinway Street\n",
      "Mott street => Mott Street\n",
      "Hudson street => Hudson Street\n",
      "west 55th street => west 55th Street\n",
      "E 45th street => E 45th Street\n",
      "E. 54th St. => E. 54th Street\n",
      "East 73rd St. => East 73rd Street\n",
      "9th St. => 9th Street\n",
      "11th St. => 11th Street\n",
      "Devoe St. => Devoe Street\n",
      "University Plz => University Plaza\n",
      "43rd Rd => 43rd Road\n",
      "Bedford avenue => Bedford Avenue\n",
      "Utica avenue => Utica Avenue\n",
      "2nd avenue => 2nd Avenue\n",
      "5th ave => 5th Avenue\n",
      "6th ave => 6th Avenue\n",
      "Union st => Union Street\n",
      "South 4th st => South 4th Street\n",
      "W 35th st => W 35th Street\n"
     ]
    }
   ],
   "source": [
    "# dictionary to store mapping between inconsistent and better street types\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Streeet\" : \"Street\",\n",
    "            \"street\" : \"Street\",\n",
    "            \"ST\" : \"Street\",\n",
    "            \"st\" : \"Street\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"ave\" : \"Avenue\",\n",
    "            \"avenue\" : \"Avenue\",\n",
    "            \"PKWY\" : \"Parkway\",\n",
    "            \"Pl\" : \"Place\",\n",
    "            \"Plz\" : \"Plaza\"\n",
    "            }\n",
    "\n",
    "# function accept street name, then do lookup to mapping dict and return updated better street name\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        try:\n",
    "            new_street_type = mapping[street_type]\n",
    "            name = name.replace(street_type, new_street_type)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    return name\n",
    "\n",
    "# Running test to make sure street names are getting updated as expected (for few street types only)\n",
    "for st_type, ways in street_types.items():\n",
    "    if st_type in mapping:\n",
    "        i = 0\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print(name, \"=>\", better_name)\n",
    "            i += 1\n",
    "            if i == 5:\n",
    "                break\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is shape_element function to transform data in required dictionary format. shape_element uses update_name function to translate street names to better names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list contains all elements which will be included to \"created\" key\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    '''\n",
    "    this function converts osm elements to node dictionary. It will format all attributes \n",
    "    and sub-elements in required model defined above section.\n",
    "    '''\n",
    "    node = {} # return dict with nodes and ways data in our data model format\n",
    "    created = {} # temp dict to store \"created\" key, this will be added to node dict\n",
    "    pos = [None, None] # temp list to store lat and log, this will be added to node dict\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :  # process only \"node\" and \"way\"\n",
    "        # store element type\n",
    "        node[\"type\"] = element.tag \n",
    "        \n",
    "        # loop through element's attributes\n",
    "        for at in element.attrib:\n",
    "            \n",
    "            # all elements in CREATED list will be grouped and stored under created key\n",
    "            if at in CREATED:\n",
    "                created[at] = element.attrib[at]\n",
    "                node[\"created\"] = created\n",
    "            \n",
    "            # store latitudes and longitudes in pos key\n",
    "            elif at in ['lat','lon']:\n",
    "                if at == \"lat\":\n",
    "                    pos[0] = float(element.attrib[at])\n",
    "                else:\n",
    "                    pos[1] = float(element.attrib[at])\n",
    "            else:\n",
    "                node[at] = element.attrib[at]\n",
    "\n",
    "        if not None in pos:\n",
    "            node[\"pos\"] = pos\n",
    "        \n",
    "        # processing inner \"tag\" element for nodes and ways\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if not problemchars.search(tag.attrib[\"k\"]): # filetering problem chars\n",
    "                \n",
    "                # selecting tags starting with \"attrib:\" to get all \"address\" key fields\n",
    "                if lower_colon.search(tag.attrib[\"k\"]) and tag.attrib[\"k\"].startswith(\"addr:\"):\n",
    "                    if \"address\" not in node:\n",
    "                        node[\"address\"] = {}\n",
    "                            \n",
    "                    key = tag.attrib[\"k\"].split(\":\")[1]\n",
    "                    if is_street_name(tag):\n",
    "                        better_name = update_name(tag.attrib[\"v\"], mapping)\n",
    "                        node[\"address\"][key] = better_name\n",
    "                    elif is_city_name(tag):\n",
    "                        uniform_city_name = update_city(tag.attrib[\"v\"], city_mapping)\n",
    "                        node[\"address\"][key] = uniform_city_name\n",
    "                    else:\n",
    "                        node[\"address\"][key] = tag.attrib[\"v\"]\n",
    "                        \n",
    "                # store all other \"tag\" as normal name-value pair\n",
    "                else:\n",
    "                    node[tag.attrib[\"k\"]] = tag.attrib[\"v\"]\n",
    "        \n",
    "        # to store nd elements under \"node_refs\" list for ways\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            if \"node_refs\" not in node:\n",
    "                node[\"node_refs\"] = []\n",
    "            node[\"node_refs\"].append(nd.attrib[\"ref\"])\n",
    "            \n",
    "        #pprint.pprint(node)\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    '''\n",
    "    This function gets osm file as input, parses the file and then using shape_element\n",
    "    function transforms data in required format. Then write data to JSON file.\n",
    "    '''\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call process map function, passing jersey_city.osm file as input.\n",
    "process_map(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outfile file : jersey_city.osm.json is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Data Overview\n",
    "\n",
    "In this section I have included few statistics of the data. Showed process to load data to MongoDB.\n",
    "Then run some MongoDB queries to get more information regarding data.\n",
    "\n",
    "### File Sizes\n",
    "Size of the original XML OSM file downloaded for Jersey City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the downloaded OSM file - jersey_city.osm: 474.760615 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "osm_file_size = os.path.getsize(filename)/1.0e6\n",
    "print(\"Size of the downloaded OSM file - {}: {} MB\".format(filename, osm_file_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the created JSON file - jersey_city.osm.json: 501.609482 MB\n"
     ]
    }
   ],
   "source": [
    "output_filename = filename +\".json\"\n",
    "json_file_size = os.path.getsize(output_filename)/1.0e6\n",
    "print(\"Size of the created JSON file - {}: {} MB\".format(output_filename, json_file_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data to MongoDB\n",
    "Now we will load jersey_city.osm.json to MongoDB.\n",
    "MongoDB instance is running locally in my machine. I will use pyMongo to connect with MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client.osm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "osm db is created. To load json file to MongoDB, I used *mongoimport* utility. I will call this mongoimport utility from command line and load data to database. I can easily script this step using python or shell scripts. \n",
    "\n",
    "mongoimport takes 3 arguments : \n",
    "db : database name -> osm\n",
    "collection : collection name -> jersey_city\n",
    "file : json format file -> jersey_city.osm.json\n",
    "\n",
    "Below is snippet output of my import:\n",
    "\n",
    "```bash\n",
    "C:\\Program Files\\MongoDB\\Server\\3.0\\bin>mongoimport --db \"osm\" --collection \"jersey_city\" --file \"C:\\Users\\Prashant\\Dropbox\\Udacity\\Data_Analyst_ND\\Data_Wrangling_with_MongoDB\\jersey_city.osm.json\"\n",
    "2015-09-07T17:12:03.073-0400    connected to: localhost\n",
    "2015-09-07T17:12:06.071-0400    [#.......................] osm.jersey_city      20.7 MB/478.3 MB (4.3%)\n",
    "2015-09-07T17:12:09.066-0400    [##......................] osm.jersey_city      41.5 MB/478.3 MB (8.7%)\n",
    "2015-09-07T17:12:12.066-0400    [###.....................] osm.jersey_city      62.2 MB/478.3 MB (13.0%)\n",
    "2015-09-07T17:12:15.067-0400    [####....................] osm.jersey_city      83.4 MB/478.3 MB (17.4%)\n",
    "2015-09-07T17:12:18.066-0400    [#####...................] osm.jersey_city      105.3 MB/478.3 MB (22.0%)\n",
    "2015-09-07T17:12:21.066-0400    [######..................] osm.jersey_city      125.3 MB/478.3 MB (26.2%)\n",
    "2015-09-07T17:12:24.067-0400    [#######.................] osm.jersey_city      143.9 MB/478.3 MB (30.1%)\n",
    "2015-09-07T17:12:27.066-0400    [########................] osm.jersey_city      164.3 MB/478.3 MB (34.3%)\n",
    "2015-09-07T17:12:30.066-0400    [#########...............] osm.jersey_city      185.8 MB/478.3 MB (38.8%)\n",
    "2015-09-07T17:12:33.067-0400    [##########..............] osm.jersey_city      207.0 MB/478.3 MB (43.3%)\n",
    "2015-09-07T17:12:36.067-0400    [###########.............] osm.jersey_city      228.2 MB/478.3 MB (47.7%)\n",
    "2015-09-07T17:12:39.066-0400    [############............] osm.jersey_city      249.9 MB/478.3 MB (52.2%)\n",
    "2015-09-07T17:12:42.067-0400    [#############...........] osm.jersey_city      270.7 MB/478.3 MB (56.6%)\n",
    "2015-09-07T17:12:45.067-0400    [##############..........] osm.jersey_city      291.7 MB/478.3 MB (61.0%)\n",
    "2015-09-07T17:12:48.066-0400    [###############.........] osm.jersey_city      311.5 MB/478.3 MB (65.1%)\n",
    "2015-09-07T17:12:51.066-0400    [################........] osm.jersey_city      332.2 MB/478.3 MB (69.4%)\n",
    "2015-09-07T17:12:54.067-0400    [#################.......] osm.jersey_city      354.2 MB/478.3 MB (74.0%)\n",
    "2015-09-07T17:12:57.066-0400    [###################.....] osm.jersey_city      380.6 MB/478.3 MB (79.6%)\n",
    "2015-09-07T17:13:00.066-0400    [####################....] osm.jersey_city      406.9 MB/478.3 MB (85.1%)\n",
    "2015-09-07T17:13:03.068-0400    [#####################...] osm.jersey_city      433.9 MB/478.3 MB (90.7%)\n",
    "2015-09-07T17:13:06.066-0400    [#######################.] osm.jersey_city      461.3 MB/478.3 MB (96.4%)\n",
    "2015-09-07T17:13:08.038-0400    imported 2033581 documents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I ran few queries on jersey_city collections to gather some stats and information on data.\n",
    "\n",
    "#### Number of Documents in Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033581"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720878"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"node\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312508"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.jersey_city.distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'Rub21_nycbuildings', 'count': 1073036},\n",
       " {'_id': 'lxbarth_nycbuildings', 'count': 135794},\n",
       " {'_id': 'ediyes_nycbuildings', 'count': 112386},\n",
       " {'_id': 'ingalls_nycbuildings', 'count': 108182},\n",
       " {'_id': 'celosia_nycbuildings', 'count': 81625}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{ \"$group\" : {\"_id\" : \"$created.user\", \"count\" : {\"$sum\" : 1}}},\n",
    "        {\"$sort\" : {\"count\" : -1}}, \n",
    "        {\"$limit\" : 5} \n",
    "        ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Zip Codes Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '11203', 'count': 11773},\n",
       " {'_id': '11215', 'count': 9533},\n",
       " {'_id': '11221', 'count': 9402},\n",
       " {'_id': '11236', 'count': 8797},\n",
       " {'_id': '11220', 'count': 8612}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{ \"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$match\" : {\"_id\" : {\"$ne\" : None}}},\n",
    "                          {\"$sort\" : {\"count\" : -1}},\n",
    "                          {\"$limit\" : 5}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Jersey City Zip Codes\n",
    "I noticed that the coverage of only jersey city zipcodes is very limited in OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '07302', 'count': 61},\n",
       " {'_id': '07306', 'count': 19},\n",
       " {'_id': '07311', 'count': 2},\n",
       " {'_id': '07304', 'count': 2},\n",
       " {'_id': '07310', 'count': 1}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get counts of Only list of Jersey City Zip Codes.\n",
    "db.jersey_city.aggregate([{\"$match\" : {\"address.postcode\" : {\"$in\" : [\"07097\",\"07302\",\"07303\",\"07304\",\"07305\",\"07306\",\"07307\",\"07308\",\"07310\",\"07311\"]} }},\n",
    "                          {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$sort\" : {\"count\" : -1}}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 City Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'New York City', 'count': 4998},\n",
       " {'_id': 'Hoboken', 'count': 504},\n",
       " {'_id': 'Jersey City', 'count': 73},\n",
       " {'_id': 'Newark', 'count': 33},\n",
       " {'_id': 'Orange', 'count': 11}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{\"$group\" : {\"_id\" : \"$address.city\", \"count\" : {\"$sum\" : 1}}}, \n",
    "                          {\"$match\" : {\"_id\" : {\"$ne\" : None}}},\n",
    "                          {\"$sort\" : {\"count\" : -1}},\n",
    "                          {\"$limit\" : 5}\n",
    "                         ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'bicycle_parking', 'count': 3895},\n",
       " {'_id': 'restaurant', 'count': 1361},\n",
       " {'_id': 'place_of_worship', 'count': 1320},\n",
       " {'_id': 'school', 'count': 954},\n",
       " {'_id': 'parking', 'count': 915}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.aggregate([{\"$match\" : {\"amenity\" : {\"$exists\" : 1}}},\n",
    "                          {\"$group\" : {\"_id\" : \"$amenity\", \"count\" : {\"$sum\" : 1 }}},\n",
    "                          {\"$sort\" : {\"count\" : -1}},\n",
    "                          {\"$limit\" : 5}\n",
    "    ])[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Additional Ideas\n",
    "\n",
    "### nycbuildings\n",
    "\n",
    "In previous section, I found that top 5 users are all following some pattern of \"nycbuildings\"\n",
    "I reserached more on this, looks like as part of NYC open data initiative last year bulk of this data were loaded to OSM.\n",
    "\n",
    "Below article contain detail on this:\n",
    "https://www.mapbox.com/blog/nyc-buildings-openstreetmap/\n",
    "\n",
    "After querying using mongodb regex, I found that 78% of this dataset is from nycbuilding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596652"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find( {\"created.user\" : {\"$regex\" : \"nycbuildings$\" } } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These nycbuildings documents doesnt have many useful information. Only few of them have address. All other useful attributes like amenities etc are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230417"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find( {\"created.user\" : {\"$regex\" : \"nycbuildings$\" }, \"address\" : {\"$exists\" : 1} } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents for TIGER and GNIS\n",
    "\n",
    "After looking more into this dataset, the data is filled with many entries for \"way\" from TIGER (Topologically Integrated Geographic Encoding and Referencing system)\n",
    "http://wiki.openstreetmap.org/wiki/TIGER\n",
    "\n",
    "There are also many entries for \"node\" from GNIS (USGS Geographic Names Information System).\n",
    "http://wiki.openstreetmap.org/wiki/USGS_GNIS\n",
    "\n",
    "As per documentation of both of these above sources (datasets), data seems outdated or incorrect.\n",
    "GNIS:ID suppose to map with OSM amenity tags, but no corresponding amenity tags are present for these GNIS:ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17388"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way document from tiger\n",
    "db.jersey_city.find( { \"type\" : \"way\", \"tiger:cfcc\" : { \"$exists\": 1 } } ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2117"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node documents from gnis\n",
    "db.jersey_city.find( { \"type\" : \"node\", \"gnis:created\" : { \"$exists\": 1 } } ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Node and Way with Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54044"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"node\", \"address.street\" : {\"$exists\" : 1}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.jersey_city.find({\"type\" : \"way\", \"address.street\" : {\"$exists\" : 1}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to presence of nycbuildings, tiger and gnis incomplete data, my dataset is not giving much useful information.\n",
    "Below are important ideas which are important to make this OSM data more useful:\n",
    "\n",
    "#### Standardrizing City Name and Zip Codes\n",
    "We can easily standardrize city names and zip codes. An API can be created or current OSM API can be expanded to create a lookup based on co-ordinates which will return uniform city names and zip codes. This API can referred while sourcing data to OSM.\n",
    "Same, can be used to add city names and zip codes to the nodes missing these info.\n",
    "\n",
    "#### Cleaning up outdated and invalid TIGER and GNIS data\n",
    "TIGER and GNIS data was loaded few years back. Many of that data needs cleaning. Outdated data needs to be indentifer and cleaned. We can use Google MAP API to cross reference OSM data and clean it whereever possible. \n",
    "\n",
    "#### nycbuildings Data can be leveraged\n",
    "For my selected map area, nycbuildings data seems latest. However, it still needs more attributes and information.\n",
    "A game or competition can be started using social network, where players can act as explorers. They will be provided with co-ordinates and they need to find informations regarding that co-ordinates. Player can get points based on that. Geo-tagging and hash-tagging can be leveraged for that.\n",
    "\n",
    "#### More crowd-sourced apps\n",
    "Many more crowd-sourced apps can be developed using OSM data, which in turn will help OSM data quality also.\n",
    "We can create social networking street parking app, where users can geo-tag different street parking all over the city. Once data is more mature, it can be developed to be more advance app which can provide real time parking spots update.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "Jersey City and the neighbouring areas data needs cleaning and mapping. NYCBuidlings data has created a nice skeleton, which can be leveraged to make this data more useful.\n",
    "In current state, it is difficult to gain any intelligence from this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
